<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Education on ~sienna</title><link>https://siennabates.com/tags/education/</link><description>Read the latest Education on ~sienna</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 15 Jan 2025 19:38:24 -0800</lastBuildDate><atom:link href="https://siennabates.com/tags/education/index.xml" rel="self" type="application/rss+xml"/><item><title>Gen AI Follow Up</title><link>https://siennabates.com/blog/2025/genaifollowup/</link><pubDate>Wed, 15 Jan 2025 19:38:24 -0800</pubDate><guid>https://siennabates.com/blog/2025/genaifollowup/</guid><description>&lt;p>More and more at my job I keep hearing about things like “if you aren’t using AI everyday or finding ways to incorporate it into your job, you’ll fall behind”. This makes me think about all the discourse about whether AI will be taking everyone’s jobs. I still firmly believe a human element is necessary for all jobs regardless of how much one believes we need to incorporate AI. I think the approach to its incorporation in the workplace day to day is fundamentally flawed. It is a powerful technology and it is really cool to see how it has evolved in such a short period. However, that does not make it some magical cure or solution to all problems, there are still problems with each platform or service. I believe many people are so in awe of its capabilities that it is often mistaken for a replacement for their actual thoughts and effort into solving a problem.&lt;/p></description><content:encoded><![CDATA[ <p>More and more at my job I keep hearing about things like “if you aren’t using AI everyday or finding ways to incorporate it into your job, you’ll fall behind”. This makes me think about all the discourse about whether AI will be taking everyone’s jobs. I still firmly believe a human element is necessary for all jobs regardless of how much one believes we need to incorporate AI. I think the approach to its incorporation in the workplace day to day is fundamentally flawed. It is a powerful technology and it is really cool to see how it has evolved in such a short period. However, that does not make it some magical cure or solution to all problems, there are still problems with each platform or service. I believe many people are so in awe of its capabilities that it is often mistaken for a replacement for their actual thoughts and effort into solving a problem.</p>
<p>Personally, I try to utilize it but it is not everyday. I think AI can be used in moderation and that its an excellent tool for skeletal frameworks for what task you might be trying to complete. I don’t think it should (in its current state) be utilized as the final product for anything, especially in academia or the workplace.</p>
<p>I spoke with my father earlier this year and he asked about my utilization habits with regards to AI and mentioned his organization did a survey about how its being used and the results showed that many if not all the men used it every day, but women were less likely to use it. I had some thoughts on that, which I think stem from sexism in the workplace. From my experience talking with other women at my current and previous jobs, we have all been subject to similar experiences in the workplace where we have had others take credit for, undermine, or criticized to no end. Trying continuously to prove we are deserving of being in the same role and working twice as hard to be prove we should be promoted. I wonder if this trend will continue as utilization becomes more widespread.</p>
 ]]></content:encoded></item><item><title>Gen AI Thoughts</title><link>https://siennabates.com/blog/2024/genaithoughts/</link><pubDate>Mon, 10 Jun 2024 19:38:24 -0800</pubDate><guid>https://siennabates.com/blog/2024/genaithoughts/</guid><description>&lt;p>We saw a massive dip in the educational quality students were getting during and post Covid. The amount of teachers retiring and discussing how their students lack basic skills for literacy and critical thinking is staggering. I see so many posts on various social medias taking specific stances or commenting about a recent issue without actually doing any reading and follow up. Like it’s absolutely fine to have a wrong stance on something (I do believe some things are fundamentally correct or not correct than up for debate on). However posing their stance as fact or because of what a specific article says and people always want a shortened version because reading is a lot of engagement and our society is moving its focus to short form content. This can be damaging because people just want to read a headline or quote and don’t actually understand it can be taken out of context and used to spread misinformation - and people just don’t care.&lt;/p></description><content:encoded><![CDATA[ <p>We saw a massive dip in the educational quality students were getting during and post Covid. The amount of teachers retiring and discussing how their students lack basic skills for literacy and critical thinking is staggering. I see so many posts on various social medias taking specific stances or commenting about a recent issue without actually doing any reading and follow up. Like it’s absolutely fine to have a wrong stance on something (I do believe some things are fundamentally correct or not correct than up for debate on). However posing their stance as fact or because of what a specific article says and people always want a shortened version because reading is a lot of engagement and our society is moving its focus to short form content. This can be damaging because people just want to read a headline or quote and don’t actually understand it can be taken out of context and used to spread misinformation - and people just don’t care.</p>
<p>But I think with the use of AI it will only exacerbate this issue. It’s like no one wants to fact check these days. I think putting AI in everything I am interested to see what kind of policies will be passed surrounding the use of AI. There’s the whole deal with Adobe recently. How AI will use our data and information? Will we ever own anything again - or are we perpetually suck in a subscription for life? (Curious to know how that as a whole affects people vs outright owning things like back in the day in a financial sense) is anything we create going to be used to train a LLM? Also who is at fault if something bad happens? Is it the company, is it on the user as their policy prevents them from acknowledging or being responsible for any wrongdoing? What if their product is used to create misinformation or content that harms others?</p>
<p>With even the most educated and knowledgeable people still having the occasional difficulty identifying when something is AI generated - how will we adjust to those who can’t tell? Will anything be “real” or human generated? I fear places like Facebook will just be AI engagement farms and I think that the jobs that are more likely at risk are newer ones than older ones. Specifically, I would bet content creators will become more permanently obsolete than tech workers. However, I also think there will be a large dip for very quickly for tech workers but the demand will be back quicker. I think the opposite will be true for content creators. I think it’ll be easier for brands to use a trained LLM to create content and for a cheaper price too and there will be less “human” advocacy for products and services. I think that with minimal media literacy, the average person won’t be able to tell the difference between an AI content creator and a human one. I think the decline could even be just as fast but the change is less noticeable to the untrained eye.</p>
 ]]></content:encoded></item></channel></rss>