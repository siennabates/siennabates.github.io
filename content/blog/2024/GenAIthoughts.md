---
title: "Gen AI Thoughts"
date: 2024-06-10T19:38:24-08:00
draft: false
tags: ["AI", "Social Media", "education"]
#summary: "Inital thoughts on GenAI."
---

We saw a massive dip in the educational quality students were getting during and post Covid. The amount of teachers retiring and discussing how their students lack basic skills for literacy and critical thinking is staggering. I see so many posts on various social medias taking specific stances or commenting about a recent issue without actually doing any reading and follow up. Like it’s absolutely fine to have a wrong stance on something (I do believe some things are fundamentally correct or not correct than up for debate on). However posing their stance as fact or because of what a specific article says and people always want a shortened version because reading is a lot of engagement and our society is moving its focus to short form content. This can be damaging because people just want to read a headline or quote and don’t actually understand it can be taken out of context and used to spread misinformation - and people just don’t care.  

But I think with the use of AI it will only exacerbate this issue. It’s like no one wants to fact check these days. I think putting AI in everything I am interested to see what kind of policies will be passed surrounding the use of AI. There’s the whole deal with Adobe recently. How AI will use our data and information? Will we ever own anything again - or are we perpetually suck in a subscription for life? (Curious to know how that as a whole affects people vs outright owning things like back in the day in a financial sense) is anything we create going to be used to train a LLM? Also who is at fault if something bad happens? Is it the company, is it on the user as their policy prevents them from acknowledging or being responsible for any wrongdoing? What if their product is used to create misinformation or content that harms others? 

With even the most educated and knowledgeable people still having the occasional difficulty identifying when something is AI generated - how will we adjust to those who can’t tell? Will anything be “real” or human generated? I fear places like Facebook will just be AI engagement farms and I think that the jobs that are more likely at risk are newer ones than older ones. Specifically, I would bet content creators will become more permanently obsolete than tech workers. However, I also think there will be a large dip for very quickly for tech workers but the demand will be back quicker. I think the opposite will be true for content creators. I think it’ll be easier for brands to use a trained LLM to create content and for a cheaper price too and there will be less “human” advocacy for products and services. I think that with minimal media literacy, the average person won’t be able to tell the difference between an AI content creator and a human one. I think the decline could even be just as fast but the change is less noticeable to the untrained eye.